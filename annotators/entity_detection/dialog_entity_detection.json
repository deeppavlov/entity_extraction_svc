{
  "chainer": {
    "in": ["x"],
    "in_y": ["y"],
    "pipe": [
      {
        "class_name": "torch_transformers_preprocessor:TorchTransformersNerPreprocessor",
        "vocab_file": "{TRANSFORMER}/vocab.txt",
        "do_lower_case": false,
        "max_seq_length": 512,
        "max_subword_length": 15,
        "token_masking_prob": 0.0,
        "from_file": true,
        "in": ["x"],
        "out": [
          "x_tokens",
          "x_subword_tokens",
          "x_subword_tok_ids",
          "startofword_markers",
          "attention_mask",
          "tokens_offsets"
        ]
      },
      {
        "id": "tag_vocab",
        "class_name": "simple_vocab",
        "unk_token": [
          "O"
        ],
        "pad_with_zeros": true,
        "save_path": "{MODEL_PATH}/tag.dict",
        "load_path": "{MODEL_PATH}/tag.dict",
        "fit_on": ["y"],
        "in": ["y"],
        "out": ["y_ind"]
      },
      {
        "class_name": "torch_transformers_sequence_tagger:TorchTransformersSequenceTagger",
        "n_tags": "#tag_vocab.len",
        "pretrained_bert": "{TRANSFORMER}",
        "from_file": true,
        "attention_probs_keep_prob": 0.5,
        "return_probas": true,
        "encoder_layer_ids": [
          -1
        ],
        "optimizer": "AdamW",
        "optimizer_parameters": {
          "lr": 2e-5,
          "weight_decay": 1e-6,
          "betas": [
            0.9,
            0.999
          ],
          "eps": 1e-6
        },
        "clip_norm": 1.0,
        "min_learning_rate": 1e-7,
        "learning_rate_drop_patience": 6,
        "learning_rate_drop_div": 1.5,
        "load_before_drop": true,
        "save_path": "{MODEL_PATH}/model",
        "load_path": "{MODEL_PATH}/model",
        "in": [
          "x_subword_tok_ids",
          "attention_mask",
          "startofword_markers"
        ],
        "in_y": ["y_ind"],
        "out": ["y_pred_ind", "probas"]
      },
      {
        "ref": "tag_vocab",
        "in": ["y_pred_ind"],
        "out": ["y_pred"]
      },
      {
        "in": ["x_tokens", "tokens_offsets", "y_pred", "probas"],
        "out": ["entities", "tags", "positions", "entities_offsets", "entity_probas"],
        "o_tag": "O",
        "ent_thres_proba": 0.7,
        "tags_file": "{NER_PATH}/tag.dict",
        "class_name": "entity_detection_parser:EntityDetectionParser"
      }
    ],
    "out": ["entities", "tags", "positions", "entities_offsets", "entity_probas"]
  },
  "train": {
    "epochs": 30,
    "batch_size": 30,
    "metrics": [
      {
        "name": "ner_f1",
        "inputs": [
          "y",
          "y_pred"
        ]
      },
      {
        "name": "ner_token_f1",
        "inputs": [
          "y",
          "y_pred"
        ]
      }
    ],
    "validation_patience": 15,
    "val_every_n_batches": 100,
    "log_every_n_batches": 100,
    "show_examples": false,
    "pytest_max_batches": 2,
    "pytest_batch_size": 8,
    "evaluation_targets": [
      "valid",
      "test"
    ],
    "class_name": "torch_trainer"
  },
  "metadata": {
    "variables": {
      "ROOT_PATH": "~/.deeppavlov",
      "DOWNLOADS_PATH": "{ROOT_PATH}/downloads",
      "MODELS_PATH": "{ROOT_PATH}/models",
      "TRANSFORMER": "{DOWNLOADS_PATH}/bert_models/bert-base-uncased",
      "MODEL_PATH": "{MODELS_PATH}/dialog_entity_detection",
      "NER_PATH": "{MODELS_PATH}/dialog_entity_detection"
    },
    "requirements": [
      "{DEEPPAVLOV_PATH}/requirements/pytorch16.txt",
      "{DEEPPAVLOV_PATH}/requirements/transformers.txt",
      "{DEEPPAVLOV_PATH}/requirements/gensim.txt",
      "{DEEPPAVLOV_PATH}/requirements/tf.txt",
      "{DEEPPAVLOV_PATH}/requirements/bert_dp.txt"
    ],
    "download": [
      {
        "url": "http://files.deeppavlov.ai/deeppavlov_data/dialog_entity_detection/dialog_entity_detection_model.tar.gz",
        "subdir": "{MODELS_PATH}/dialog_entity_detection"
      },
      {
        "url": "http://files.deeppavlov.ai/deeppavlov_data/dialog_entity_detection/bert-base-uncased.tar.gz",
        "subdir": "{DOWNLOADS_PATH}/bert_models/bert-base-uncased"
      }
    ]
  }
}
