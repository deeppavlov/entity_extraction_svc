{
  "dataset_reader": {
    "class_name": "sq_reader",
    "data_path": "{DOWNLOADS_PATH}/ontonotes/ontonotes_extended.pickle"
  },
  "dataset_iterator": {
    "class_name": "data_learning_iterator"
  },
  "chainer": {
    "in": ["x"],
    "in_y": ["y"],
    "pipe": [
      {
        "class_name": "src.torch_transformers_preprocessor:TorchTransformersNerPreprocessor",
        "vocab_file": "{TRANSFORMER}",
        "do_lower_case": false,
        "max_seq_length": 512,
        "max_subword_length": 15,
        "token_masking_prob": 0.0,
        "in": ["x"],
        "out": ["x_tokens", "x_subword_tokens", "x_subword_tok_ids", "startofword_markers", "attention_mask", "tokens_offsets"]
      },
      {
        "id": "tag_vocab",
        "class_name": "simple_vocab",
        "unk_token": ["O"],
        "pad_with_zeros": true,
        "save_path": "{MODEL_PATH}/tag.dict",
        "load_path": "{MODEL_PATH}/tag.dict",
        "fit_on": ["y"],
        "in": ["y"],
        "out": ["y_ind"]
      },
      {
        "class_name": "src.torch_transformers_sequence_tagger:TorchTransformersSequenceTagger",
        "n_tags": "#tag_vocab.len",
        "pretrained_bert": "{TRANSFORMER}",
        "attention_probs_keep_prob": 0.5,
        "return_probas": true,
        "encoder_layer_ids": [-1],
        "optimizer": "AdamW",
        "optimizer_parameters": {
          "lr": 2e-05,
          "weight_decay": 1e-06,
          "betas": [0.9, 0.999],
          "eps": 1e-06
        },
        "clip_norm": 1.0,
        "min_learning_rate": 1e-07,
        "learning_rate_drop_patience": 3,
        "learning_rate_drop_div": 1.5,
        "load_before_drop": true,
        "save_path": "{MODEL_PATH}/model",
        "load_path": "{MODEL_PATH}/model",
        "in": ["x_subword_tok_ids", "attention_mask", "startofword_markers"],
        "in_y": ["y_ind"],
        "out": ["y_pred_ind", "probas"]
      },
      {
        "ref": "tag_vocab",
        "in": ["y_pred_ind"],
        "out": ["y_pred"]
      }
    ],
    "out": ["x_tokens", "tokens_offsets", "y_pred", "probas"]
  },
  "train": {
    "epochs": 5,
    "batch_size": 16,
    "metrics": [
      {
        "name": "ner_f1",
        "inputs": ["y", "y_pred"]
      },
      {
        "name": "ner_token_f1",
        "inputs": ["y", "y_pred"]
      }
    ],
    "validation_patience": 50,
    "val_every_n_batches": 1000,
    "log_every_n_batches": 1000,
    "show_examples": false,
    "pytest_max_batches": 2,
    "pytest_batch_size": 8,
    "evaluation_targets": ["valid", "test"],
    "class_name": "torch_trainer"
  },
  "metadata": {
    "variables": {
      "ROOT_PATH": "~/.deeppavlov",
      "DOWNLOADS_PATH": "{ROOT_PATH}/downloads",
      "MODELS_PATH": "{ROOT_PATH}/models",
      "TRANSFORMER": "{DOWNLOADS_PATH}/torch_bert_models/roberta_tiny_cased",
      "MODEL_PATH": "{MODELS_PATH}/ner_ontonotes_bert_torch/roberta-tiny-cased"
    },
    "download": [
      {
        "url": "http://files.deeppavlov.ai/v1/ner/ner_ontonotes_tinyroberta.tar.gz",
        "subdir": "{MODEL_PATH}"
      },
      {
        "url": "http://files.deeppavlov.ai/deeppavlov_data/entity_linking/roberta_tiny_cased.tar.gz",
        "subdir": "{DOWNLOADS_PATH}/torch_bert_models/roberta_tiny_cased"
      }
    ]
  }
}
